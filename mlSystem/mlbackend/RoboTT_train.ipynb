{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "CPU = False\n",
    "\n",
    "import os\n",
    "if CPU:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from ssd_model import SSD512 as Model\n",
    "from ssd_utils import PriorUtil\n",
    "from ssd_data import InputGenerator\n",
    "from ssd_data import preprocess\n",
    "from ssd_training import SSDLoss\n",
    "from ssd_metric import evaluate_results\n",
    "from utils.model import load_weights\n",
    "from utils.training import Logger, LearningRateDecay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = './data/RoboTT/'\n",
    "#data_path = './data/RoboTT_extra/'\n",
    "\n",
    "from data_robott import GTUtility\n",
    "gt_util = GTUtility(data_path)\n",
    "gt_util_train, gt_util_val = gt_util.split(0.8)\n",
    "print(gt_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment = 'robott'\n",
    "\n",
    "model = Model(num_classes=gt_util.num_classes)\n",
    "\n",
    "prior_util = PriorUtil(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize with SSD model\n",
    "load_weights(model, './models/ssd512_voc_weights_fixed.hdf5')\n",
    "\n",
    "freeze = ['conv1_1', 'conv1_2',\n",
    "          'conv2_1', 'conv2_2',\n",
    "          'conv3_1', 'conv3_2', 'conv3_3',\n",
    "          #'conv4_1', 'conv4_2', 'conv4_3',\n",
    "          #'conv5_1', 'conv5_2', 'conv5_3',\n",
    "         ]\n",
    "for layer in model.layers:\n",
    "    layer.trainable = not layer.name in freeze\n",
    "\n",
    "initial_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# continue training\n",
    "#load_weights(model, './checkpoints/201708072158_ssd_voc/weights.400.h5')\n",
    "#load_weights(model, './checkpoints/201709202151_robott/weights.067.h5'); initial_epoch = 68\n",
    "#load_weights(model, './checkpoints/201709231742_robott/weights.058.h5'); initial_epoch = 59\n",
    "load_weights(model, './checkpoints/201710052244_robott/weights.118.h5'); initial_epoch = 119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 24\n",
    "\n",
    "options = {\n",
    "    'vflip_prob': 0.0, \n",
    "    'hflip_prob': 0.0, \n",
    "    'do_crop': True, \n",
    "    'crop_area_range': [0.6, 1.0]\n",
    "}\n",
    "gen_train = InputGenerator(gt_util_train, prior_util, batch_size, model.image_size, augmentation=True, **options)\n",
    "gen_val = InputGenerator(gt_util_val, prior_util, batch_size, model.image_size, augmentation=True, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkdir = './checkpoints/' + time.strftime('%Y%m%d%H%M') + '_' + experiment\n",
    "if not os.path.exists(checkdir):\n",
    "    os.makedirs(checkdir)\n",
    "\n",
    "with open(checkdir+'/source.py','wb') as f:\n",
    "    source = ''.join(['# In[%i]\\n%s\\n\\n' % (i, In[i]) for i in range(len(In))])\n",
    "    f.write(source.encode())\n",
    "\n",
    "#optim = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "optim = keras.optimizers.SGD(lr=1e-3, momentum=0.9, decay=0, nesterov=True)\n",
    "\n",
    "# weight decay\n",
    "regularizer = keras.regularizers.l2(5e-4) # None if disabled\n",
    "for l in model.layers:\n",
    "    if l.__class__.__name__.startswith('Conv'):\n",
    "        l.kernel_regularizer = regularizer\n",
    "\n",
    "loss = SSDLoss(alpha=1.0, neg_pos_ratio=3.0)\n",
    "\n",
    "model.compile(optimizer=optim,\n",
    "              loss=loss.compute,\n",
    "              metrics=loss.metrics)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(checkdir+'/weights.{epoch:03d}.h5', verbose=1, save_weights_only=True),\n",
    "    Logger(checkdir),\n",
    "    LearningRateDecay()\n",
    "]\n",
    "\n",
    "history = model.fit_generator(gen_train.generate(), #generator, \n",
    "                              gen_train.num_batches, #steps_per_epoch, \n",
    "                              epochs=epochs, \n",
    "                              verbose=1, \n",
    "                              callbacks=callbacks, \n",
    "                              validation_data=gen_val.generate(), \n",
    "                              validation_steps=gen_val.num_batches, \n",
    "                              class_weight=None, \n",
    "                              #max_queue_size=10, \n",
    "                              workers=1, \n",
    "                              #use_multiprocessing=False, \n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Example results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#gt_util = gt_util_train\n",
    "gt_util = gt_util_val\n",
    "#np.random.seed(1337)\n",
    "idxs = np.random.randint(0, gt_util.num_samples, 16)\n",
    "h, w = model.image_size\n",
    "\n",
    "data = []\n",
    "inputs = []\n",
    "images = []\n",
    "for i in idxs:\n",
    "    img_path = os.path.join(gt_util.image_path, gt_util.image_names[i])\n",
    "    img = cv2.imread(img_path)\n",
    "    gt = gt_util.data[i]\n",
    "    \n",
    "    # random cropping\n",
    "    for _ in range(32): # retries if lose ground truth\n",
    "        tmp_img, tmp_gt = gen_val.random_sized_crop(img, gt)\n",
    "        if len(tmp_gt) > 0: break\n",
    "    if len(tmp_gt) == 0:\n",
    "        print('no gt', gt_util.image_names[i])\n",
    "        continue\n",
    "    else:\n",
    "        img = tmp_img\n",
    "        gt = tmp_gt\n",
    "        \n",
    "    inputs.append(preprocess(img, model.image_size))\n",
    "    img = cv2.resize(img, (w,h), cv2.INTER_LINEAR)\n",
    "    img = img[:, :, (2,1,0)] # BGR to RGB\n",
    "    img = img / 256.\n",
    "    images.append(img)\n",
    "    data.append(gt)\n",
    "inputs = np.asarray(inputs)\n",
    "\n",
    "preds = model.predict(inputs, batch_size=1, verbose=1)\n",
    "\n",
    "checkdir = './checkpoints/201710052244_robott'\n",
    "for fl in glob.glob('%s/result_*' % (checkdir,)):\n",
    "    os.remove(fl)\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    res = prior_util.decode(preds[i], confidence_threshold=0.2, keep_top_k=3)\n",
    "    if len(data[i]) > 0:\n",
    "        plt.figure(figsize=[10]*2)\n",
    "        plt.imshow(images[i])\n",
    "        prior_util.plot_results(res, classes=gt_util.classes, show_labels=True, gt_data=data[i])\n",
    "        plt.savefig('%s/result_%03d.jpg' % (checkdir, i))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gt_util = gt_util_train\n",
    "gt_util = gt_util_val\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "gt_all = []\n",
    "dt_all = []\n",
    "in_batch = []\n",
    "gt_batch = []\n",
    "\n",
    "for i in tqdm(range(gt_util.num_samples)):\n",
    "    img_path = os.path.join(gt_util.image_path, gt_util.image_names[i])\n",
    "    img = cv2.imread(img_path)\n",
    "    gt = gt_util.data[i]\n",
    "    \n",
    "    if True:\n",
    "        # random cropping\n",
    "        for _ in range(32): # retries if lose ground truth\n",
    "            tmp_img, tmp_gt = gen_val.random_sized_crop(img, gt)\n",
    "            if len(tmp_gt) > 0: break\n",
    "        if len(tmp_gt) == 0:\n",
    "            print('no gt', gt_util.image_names[i])\n",
    "            #continue\n",
    "        else:\n",
    "            img = tmp_img\n",
    "            gt = tmp_gt\n",
    "    \n",
    "    in_batch.append(preprocess(img, model.image_size))\n",
    "    gt_batch.append(gt)\n",
    "    \n",
    "    # images for plot\n",
    "    #img_h, img_w = model.image_size\n",
    "    #img = cv2.resize(img, (img_w, img_h), cv2.INTER_LINEAR)\n",
    "    #img = img[:, :, (2,1,0)] # BGR to RGB\n",
    "    #img = img / 256.\n",
    "    #images.append(img)\n",
    "    \n",
    "    if len(in_batch) == batch_size or i == gt_util.num_samples-1:\n",
    "        preds = model.predict(np.asarray(in_batch), batch_size=batch_size, verbose=0)\n",
    "        for j in range(len(preds)):\n",
    "            dt = prior_util.decode(preds[j], confidence_threshold=0.01, keep_top_k=400, fast_nms=False)\n",
    "            gt_all.append(gt_batch[j])\n",
    "            dt_all.append(dt)\n",
    "        in_batch = []\n",
    "        gt_batch = []\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                          TP       FP       FN     AP   IoU MaxPreds\n",
    "training, random cropping\n",
    "Sum / mAP              38937     8714     8714  0.805 @ 0.5 1\n",
    "Sum / mAP              40601   435909     7050  0.813 @ 0.5 10\n",
    "Sum / mAP              41874  4723226     5777  0.814 @ 0.5 100\n",
    "training, no cropping\n",
    "Sum / mAP              35604    12047    12047  0.736 @ 0.5 1\n",
    "Sum / mAP              37437   439073    10214  0.741 @ 0.5 10\n",
    "Sum / mAP              39358  4725742     8293  0.742 @ 0.5 100\n",
    "validation, random cropping\n",
    "Sum / mAP               9566     2347     2347  0.781 @ 0.5 1\n",
    "Sum / mAP              10033   109097     1880  0.790 @ 0.5 10\n",
    "Sum / mAP              10367  1180933     1546  0.791 @ 0.5 100\n",
    "validation, no cropping\n",
    "Sum / mAP               8827     3086     3086  0.721 @ 0.5 1\n",
    "Sum / mAP               9318   109812     2595  0.729 @ 0.5 10\n",
    "Sum / mAP               9744  1181556     2169  0.730 @ 0.5 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_results(gt_all, dt_all, gt_util, iou_thresh=0.1, max_dets=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Detections speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "preds = model.predict(inputs[None,0,:,:,:], batch_size=1, verbose=0)\n",
    "res = prior_util.decode(preds[0], confidence_threshold=0.2, keep_top_k=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "GeForce GTX 1080 Ti\n",
    "    39.6 ms ± 1.04 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz\n",
    "    1.5 s ± 1.14 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_dir = './data/images/test_images_robott/'\n",
    "\n",
    "inputs = []\n",
    "images = []\n",
    "for img_path in glob.glob(img_dir+'/20171019_*'):\n",
    "    img = cv2.imread(img_path)\n",
    "    inputs.append(preprocess(img, model.image_size))\n",
    "    h, w = model.image_size\n",
    "    img = cv2.resize(img, (w,h), cv2.INTER_LINEAR)\n",
    "    img = img[:, :, (2,1,0)] # BGR to RGB\n",
    "    img = img / 256.\n",
    "    images.append(img)\n",
    "inputs = np.asarray(inputs)\n",
    "    \n",
    "preds = model.predict(inputs, batch_size=1, verbose=1)\n",
    "\n",
    "checkdir = img_dir\n",
    "for fl in glob.glob('%s/result_*' % (checkdir,)):\n",
    "    os.remove(fl)\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    res = prior_util.decode(preds[i], confidence_threshold=0.2, keep_top_k=1)\n",
    "    \n",
    "    plt.figure(figsize=[10]*2)\n",
    "    plt.imshow(images[i])\n",
    "    print(len(res))\n",
    "    prior_util.plot_results(res, classes=gt_util.classes, show_labels=True)\n",
    "    plt.savefig('%s/result_%03d.jpg' % (checkdir, i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
